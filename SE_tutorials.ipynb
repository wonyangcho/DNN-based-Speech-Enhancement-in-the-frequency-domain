{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "CRN_SE.ipynb",
   "provenance": [],
   "collapsed_sections": [
    "Or2ADw_Pf6eF",
    "xFcCvs4TqTLI",
    "BFDBtQxonGHk",
    "rEOtu8Fsn0Wa",
    "zY_EN6pdnv1G",
    "8dr6psVdoMPJ",
    "t-608O_vONfP",
    "d3CmmLgnoOpz",
    "pDKYZuA-oSgZ",
    "CJZFyj_toVbj"
   ]
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Or2ADw_Pf6eF",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Licence"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "pbAI2-fUf8UC",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "https://github.com/seorim0/Speech_enhancement_with_Pytorch\n",
    "\n",
    "MIT License\n",
    "\n",
    "Copyright (c) 2021 seorim0\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "SOFTWARE."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xFcCvs4TqTLI",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Requirement"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5P2MGVfaPt9B",
    "outputId": "af63fb4b-6dd2-495c-83bd-2af46e092563",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# # For additional installation of libraries not included in the colab main library\n",
    "# !pip install \"library_name\"\n",
    "!pip install pesq\n",
    "!pip install pystoi"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pesq in /usr/local/lib/python3.7/dist-packages (0.0.3)\n",
      "Collecting pystoi\n",
      "  Downloading pystoi-0.3.3.tar.gz (7.0 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pystoi) (1.19.5)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pystoi) (1.4.1)\n",
      "Building wheels for collected packages: pystoi\n",
      "  Building wheel for pystoi (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for pystoi: filename=pystoi-0.3.3-py2.py3-none-any.whl size=7793 sha256=4b3f5991ad63a316047c2ab9f983f4f7216a7f059fc75df4c0335555ec164e4d\n",
      "  Stored in directory: /root/.cache/pip/wheels/46/4a/ad/3ab460193ed0535430b4b1575f255aa6bae69df17453628e86\n",
      "Successfully built pystoi\n",
      "Installing collected packages: pystoi\n",
      "Successfully installed pystoi-0.3.3\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "CTpjvFJwsbPn",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import math\n",
    "import torch\n",
    "import shutil\n",
    "import logging\n",
    "import numpy as np\n",
    "from pesq import pesq\n",
    "import torch.nn as nn\n",
    "from pystoi import stoi\n",
    "from scipy import interpolate\n",
    "import matplotlib.pylab as plt\n",
    "import scipy.io.wavfile as wav\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from scipy.signal import get_window\n",
    "from torch.utils.data import Dataset, DataLoader"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BFDBtQxonGHk",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# config"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ci1GVuiPnB4L",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "8a419689-3393-4fe2-ec74-c5dc689831ad",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "\"\"\"\n",
    "Configuration for train_interface\n",
    "\n",
    "You can check the essential information,\n",
    "and if you want to change model structure or training method,\n",
    "you have to change this file.\n",
    "\"\"\"\n",
    "#######################################################################\n",
    "#                                 path                                #\n",
    "#######################################################################\n",
    "job_dir = './'  # 'FILE PATH for saving models' \n",
    "chkpt_model = None  # 'FILE PATH (if you have pretrained model..)'\n",
    "chkpt = str(\"EPOCH\")  \n",
    "if chkpt_model is not None:\n",
    "    chkpt_path = job_dir + chkpt_model + '/chkpt_' + chkpt + '.pt'\n",
    "\n",
    "#######################################################################\n",
    "#                         possible setting                            #\n",
    "#######################################################################\n",
    "# the list you can do\n",
    "model_list = ['CRN']\n",
    "loss_list = ['MSE', 'SDR', 'SI-SNR', 'SI-SDR']\n",
    "mask_type = ['Direct(None make)', 'E', 'C', 'R']\n",
    "window_type = ['hanning']\n",
    "\n",
    "# experiment number setting\n",
    "expr_num = 'EXPERIMENT_NUMBER'\n",
    "DEVICE = 'cuda'  # if you want to run the code with 'cpu', change 'cpu'\n",
    "#######################################################################\n",
    "#                           current setting                           #\n",
    "#######################################################################\n",
    "current_model = model_list[0]\n",
    "current_loss = loss_list[0]\n",
    "\n",
    "masking_mode = mask_type[1]\n",
    "window = window_type[0]\n",
    "skip_type = True   # False, if you want to remove 'skip connection'\n",
    "direct_mapping = True if masking_mode == 'Direct(None make)'else False\n",
    "\n",
    "# hyper-parameters\n",
    "max_epochs = 100\n",
    "learning_rate = 0.001\n",
    "batch = 10\n",
    "\n",
    "# kernel size\n",
    "dccrn_kernel_num = [32, 64, 128, 256, 256, 256]\n",
    "#######################################################################\n",
    "#                         model information                           #\n",
    "#######################################################################\n",
    "fs = 16000\n",
    "win_len = 400\n",
    "win_inc = 100\n",
    "ola_ratio = win_inc / win_len\n",
    "fft_len = 512 #2048 #512\n",
    "sam_sec = fft_len / fs\n",
    "frm_samp = fs * (fft_len / fs)\n",
    "\n",
    "rnn_layers = 2\n",
    "rnn_input_size = 512 \n",
    "rnn_units = 128\n",
    "#######################################################################\n",
    "#                      setting error check                            #\n",
    "#######################################################################\n",
    "# if the setting is wrong, print error message\n",
    "\n",
    "#######################################################################\n",
    "#                           print setting                             #\n",
    "#######################################################################\n",
    "print('--------------------  C  O  N  F  I  G  ----------------------')\n",
    "print('--------------------------------------------------------------')\n",
    "print('MODEL INFO : {}'.format(current_model))\n",
    "print('LOSS INFO : {}'.format(current_loss))\n",
    "print('SKIP : {}'.format(skip_type))\n",
    "print('MASKING INFO : {}'.format(masking_mode))\n",
    "print('\\nBATCH : {}'.format(batch))\n",
    "print('LEARNING RATE : {}'.format(learning_rate))\n",
    "print('--------------------------------------------------------------')\n",
    "print('--------------------------------------------------------------\\n')\n"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "--------------------  C  O  N  F  I  G  ----------------------\n",
      "--------------------------------------------------------------\n",
      "MODEL INFO : CRN\n",
      "LOSS INFO : SDR\n",
      "SKIP : True\n",
      "MASKING INFO : E\n",
      "\n",
      "BATCH : 10\n",
      "LEARNING RATE : 0.001\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rEOtu8Fsn0Wa",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "y7BnscOrn3CY",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "def create_dataloader(mode, type=0, snr=0):\n",
    "    if mode == 'train':\n",
    "        return DataLoader(\n",
    "            dataset=Wave_Dataset(mode, type, snr),\n",
    "            batch_size=batch,\n",
    "            shuffle=True,\n",
    "            num_workers=0,\n",
    "            pin_memory=True,\n",
    "            drop_last=True,\n",
    "            sampler=None\n",
    "        )\n",
    "    elif mode == 'valid':\n",
    "        return DataLoader(\n",
    "            dataset=Wave_Dataset(mode, type, snr),\n",
    "            batch_size=batch, shuffle=False, num_workers=0\n",
    "        )\n",
    "\n",
    "class Wave_Dataset(Dataset):\n",
    "    def __init__(self, mode, type, snr):\n",
    "        # load data\n",
    "        if mode == 'train':\n",
    "            self.mode = 'train'\n",
    "            print('<Training dataset>')\n",
    "            print('Load the data...')\n",
    "            self.input = np.ones((300, 2, 16000))\n",
    "            # self.input_path = \"\"DATASET_FILE_PATH\"\"\n",
    "            # self.input = np.load(self.input_path)\n",
    "        elif mode == 'valid':\n",
    "            self.mode = 'valid'\n",
    "            print('<Validation dataset>')\n",
    "            print('Load the data...')\n",
    "            self.input = np.ones((50, 2, 16000))\n",
    "            # self.input_path = \"\"DATASET_FILE_PATH\"\"\n",
    "            # self.input = np.load(self.input_path)\n",
    "            # # if you want to use a part of the dataset\n",
    "            # self.input = self.input[:500]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "            inputs = self.input[idx][0]\n",
    "            targets = self.input[idx][1]\n",
    "\n",
    "            # transform to torch from numpy\n",
    "            inputs = torch.from_numpy(inputs)\n",
    "            targets = torch.from_numpy(targets)\n",
    "\n",
    "            return inputs, targets"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zY_EN6pdnv1G",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Tools for model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_qhcrPGhoLKJ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "############################################################################\n",
    "#                         for convolutional STFT                           #\n",
    "############################################################################\n",
    "# this is from conv_stft https://github.com/huyanxin/DeepComplexCRN\n",
    "def init_kernels(win_len, win_inc, fft_len, win_type=None, invers=False):\n",
    "    if win_type == 'None' or win_type is None:\n",
    "        window = np.ones(win_len)\n",
    "    else:\n",
    "        window = get_window(win_type, win_len, fftbins=True)  # **0.5\n",
    "\n",
    "    N = fft_len\n",
    "    fourier_basis = np.fft.rfft(np.eye(N))[:win_len]\n",
    "    real_kernel = np.real(fourier_basis)\n",
    "    imag_kernel = np.imag(fourier_basis)\n",
    "    kernel = np.concatenate([real_kernel, imag_kernel], 1).T\n",
    "\n",
    "    if invers:\n",
    "        kernel = np.linalg.pinv(kernel).T\n",
    "\n",
    "    kernel = kernel * window\n",
    "    kernel = kernel[:, None, :]\n",
    "    return torch.from_numpy(kernel.astype(np.float32)), torch.from_numpy(window[None, :, None].astype(np.float32))\n",
    "\n",
    "\n",
    "class ConvSTFT(nn.Module):\n",
    "\n",
    "    def __init__(self, win_len, win_inc, fft_len=None, win_type='hamming', feature_type='real', fix=True):\n",
    "        super(ConvSTFT, self).__init__()\n",
    "\n",
    "        if fft_len == None:\n",
    "            self.fft_len = np.int(2 ** np.ceil(np.log2(win_len)))\n",
    "        else:\n",
    "            self.fft_len = fft_len\n",
    "\n",
    "        kernel, _ = init_kernels(win_len, win_inc, self.fft_len, win_type)\n",
    "        # self.weight = nn.Parameter(kernel, requires_grad=(not fix))\n",
    "        self.register_buffer('weight', kernel)\n",
    "        self.feature_type = feature_type\n",
    "        self.stride = win_inc\n",
    "        self.win_len = win_len\n",
    "        self.dim = self.fft_len\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        if inputs.dim() == 2:\n",
    "            inputs = torch.unsqueeze(inputs, 1)\n",
    "        inputs = F.pad(inputs, [self.win_len - self.stride, self.win_len - self.stride])\n",
    "        outputs = F.conv1d(inputs, self.weight, stride=self.stride)\n",
    "\n",
    "        if self.feature_type == 'complex':\n",
    "            return outputs\n",
    "        else:\n",
    "            dim = self.dim // 2 + 1\n",
    "            real = outputs[:, :dim, :]\n",
    "            imag = outputs[:, dim:, :]\n",
    "            mags = torch.sqrt(real ** 2 + imag ** 2)\n",
    "            phase = torch.atan2(imag, real)\n",
    "            return mags, phase\n",
    "\n",
    "\n",
    "class ConviSTFT(nn.Module):\n",
    "\n",
    "    def __init__(self, win_len, win_inc, fft_len=None, win_type='hamming', feature_type='real', fix=True):\n",
    "        super(ConviSTFT, self).__init__()\n",
    "        if fft_len == None:\n",
    "            self.fft_len = np.int(2 ** np.ceil(np.log2(win_len)))\n",
    "        else:\n",
    "            self.fft_len = fft_len\n",
    "        kernel, window = init_kernels(win_len, win_inc, self.fft_len, win_type, invers=True)\n",
    "        # self.weight = nn.Parameter(kernel, requires_grad=(not fix))\n",
    "        self.register_buffer('weight', kernel)\n",
    "        self.feature_type = feature_type\n",
    "        self.win_type = win_type\n",
    "        self.win_len = win_len\n",
    "        self.stride = win_inc\n",
    "        self.dim = self.fft_len\n",
    "        self.register_buffer('window', window)\n",
    "        self.register_buffer('enframe', torch.eye(win_len)[:, None, :])\n",
    "\n",
    "    def forward(self, inputs, phase=None):\n",
    "        \"\"\"\n",
    "        inputs : [B, N+2, T] (complex spec) or [B, N//2+1, T] (mags)\n",
    "        phase: [B, N//2+1, T] (if not none)\n",
    "        \"\"\"\n",
    "\n",
    "        if phase is not None:\n",
    "            real = inputs * torch.cos(phase)\n",
    "            imag = inputs * torch.sin(phase)\n",
    "            inputs = torch.cat([real, imag], 1)\n",
    "\n",
    "        outputs = F.conv_transpose1d(inputs, self.weight, stride=self.stride)\n",
    "\n",
    "        # this is from torch-stft: https://github.com/pseeth/torch-stft\n",
    "        t = self.window.repeat(1, 1, inputs.size(-1)) ** 2\n",
    "        coff = F.conv_transpose1d(t, self.enframe, stride=self.stride)\n",
    "\n",
    "        outputs = outputs / (coff + 1e-8)\n",
    "\n",
    "        outputs = outputs[..., self.win_len - self.stride:-(self.win_len - self.stride)]\n",
    "\n",
    "        return outputs\n",
    "\n",
    "\n",
    "############################################################################\n",
    "#                             for complex rnn                              #\n",
    "############################################################################\n",
    "def get_casual_padding1d():\n",
    "    pass\n",
    "\n",
    "\n",
    "def get_casual_padding2d():\n",
    "    pass\n",
    "\n",
    "\n",
    "class cPReLU(nn.Module):\n",
    "\n",
    "    def __init__(self, complex_axis=1):\n",
    "        super(cPReLU, self).__init__()\n",
    "        self.r_prelu = nn.PReLU()\n",
    "        self.i_prelu = nn.PReLU()\n",
    "        self.complex_axis = complex_axis\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        real, imag = torch.chunk(inputs, 2, self.complex_axis)\n",
    "        real = self.r_prelu(real)\n",
    "        imag = self.i_prelu(imag)\n",
    "        return torch.cat([real, imag], self.complex_axis)\n",
    "\n",
    "\n",
    "############################################################################\n",
    "#                         for data normalization                           #\n",
    "############################################################################\n",
    "class RealConv2d(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size=(1, 1),\n",
    "            stride=(1, 1),\n",
    "            padding=(0, 0),\n",
    "            dilation=1,\n",
    "            groups=1,\n",
    "            causal=True,\n",
    "            complex_axis=1,\n",
    "    ):\n",
    "        '''\n",
    "            in_channels: real+imag\n",
    "            out_channels: real+imag\n",
    "            kernel_size : input [B,C,D,T] kernel size in [D,T]\n",
    "            padding : input [B,C,D,T] padding in [D,T]\n",
    "            causal: if causal, will padding time dimension's left side,\n",
    "                    otherwise both\n",
    "\n",
    "        '''\n",
    "        super(RealConv2d, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.causal = causal\n",
    "        self.groups = groups\n",
    "        self.dilation = dilation\n",
    "\n",
    "        self.conv = nn.Conv2d(self.in_channels, self.out_channels, kernel_size, self.stride,\n",
    "                                   padding=[self.padding[0], 0], dilation=self.dilation, groups=self.groups)\n",
    "\n",
    "        nn.init.normal_(self.conv.weight.data, std=0.05)\n",
    "        nn.init.constant_(self.conv.bias, 0.)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        if self.padding[1] != 0 and self.causal:\n",
    "            inputs = F.pad(inputs, [self.padding[1], 0, 0, 0])  ## [width left, width right, height left, height right]\n",
    "        else:\n",
    "            inputs = F.pad(inputs, [self.padding[1], self.padding[1], 0, 0])\n",
    "\n",
    "        out = self.conv(inputs)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class RealConvTranspose2d(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size=(1, 1),\n",
    "            stride=(1, 1),\n",
    "            padding=(0, 0),\n",
    "            output_padding=(0, 0),\n",
    "            groups=1\n",
    "    ):\n",
    "        '''\n",
    "            in_channels: real+imag\n",
    "            out_channels: real+imag\n",
    "        '''\n",
    "        super(RealConvTranspose2d, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.output_padding = output_padding\n",
    "        self.groups = groups\n",
    "\n",
    "        self.conv = nn.ConvTranspose2d(self.in_channels, self.out_channels, kernel_size, self.stride,\n",
    "                                            padding=self.padding, output_padding=output_padding, groups=self.groups)\n",
    "\n",
    "        nn.init.normal_(self.conv.weight.data, std=0.05)\n",
    "        nn.init.constant_(self.conv.bias, 0.)\n",
    "\n",
    "        # # weight standardization\n",
    "        # self.real_conv = ConvTranspose2d(self.in_channels, self.out_channels, kernel_size, self.stride,\n",
    "        #                                     padding=self.padding, output_padding=output_padding, groups=self.groups)\n",
    "        # self.imag_conv = ConvTranspose2d(self.in_channels, self.out_channels, kernel_size, self.stride,\n",
    "        #                                     padding=self.padding, output_padding=output_padding, groups=self.groups)\n",
    "        # self.complex_axis = complex_axis\n",
    "        #\n",
    "        # nn.init.constant_(self.real_conv.bias, 0.)\n",
    "        # nn.init.constant_(self.imag_conv.bias, 0.)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "\n",
    "        out = self.conv(inputs)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "############################################################################\n",
    "#                         for data normalization                           #\n",
    "############################################################################\n",
    "# get mu and sig\n",
    "def get_mu_sig(data):\n",
    "    \"\"\"Compute mean and standard deviation vector of input data\n",
    "\n",
    "    Returns:\n",
    "        mu: mean vector (#dim by one)\n",
    "        sig: standard deviation vector (#dim by one)\n",
    "    \"\"\"\n",
    "    # Initialize array.\n",
    "    data_num = len(data)\n",
    "    mu_utt = []\n",
    "    tmp_utt = []\n",
    "    for n in range(data_num):\n",
    "        dim = len(data[n])\n",
    "        mu_utt_tmp = np.zeros(dim)\n",
    "        mu_utt.append(mu_utt_tmp)\n",
    "\n",
    "        tmp_utt_tmp = np.zeros(dim)\n",
    "        tmp_utt.append(tmp_utt_tmp)\n",
    "\n",
    "    # Get mean.\n",
    "    for n in range(data_num):\n",
    "        mu_utt[n] = np.mean(data[n], 0)\n",
    "    mu = mu_utt\n",
    "\n",
    "    # Get standard deviation.\n",
    "    for n in range(data_num):\n",
    "        tmp_utt[n] = np.mean(np.square(data[n] - mu[n]), 0)\n",
    "    sig = np.sqrt(tmp_utt)\n",
    "\n",
    "    # Assign unit variance.\n",
    "    for n in range(len(sig)):\n",
    "        if sig[n] < 1e-5:\n",
    "            sig[n] = 1.0\n",
    "    return np.float16(mu), np.float16(sig)\n",
    "\n",
    "\n",
    "def get_statistics_inp(inp):\n",
    "    \"\"\"Get statistical parameter of input data.\n",
    "\n",
    "    Args:\n",
    "        inp: input data\n",
    "\n",
    "    Returns:\n",
    "        mu_inp: mean vector of input data\n",
    "        sig_inp: standard deviation vector of input data\n",
    "    \"\"\"\n",
    "\n",
    "    mu_inp, sig_inp = get_mu_sig(inp)\n",
    "\n",
    "    return mu_inp, sig_inp\n",
    "\n",
    "\n",
    "# normalize [-1 1]\n",
    "def normalize_dataset(dataset):\n",
    "    for i in range(len(dataset)):\n",
    "            noisy_max = np.max(abs(dataset[i][0]))\n",
    "            dataset[i][0] = dataset[i][0] / noisy_max\n",
    "\n",
    "            clean_max = np.max(abs(dataset[i][1]))\n",
    "            dataset[i][1] = dataset[i][1] / clean_max\n",
    "    return dataset\n",
    "\n",
    "\n",
    "############################################################################\n",
    "#                       for plotting the samples                           #\n",
    "############################################################################\n",
    "def hann_window(win_samp):\n",
    "    tmp = np.arange(1, win_samp + 1, 1.0, dtype=np.float64)\n",
    "    window = 0.5 - 0.5 * np.cos((2.0 * np.pi * tmp) / (win_samp + 1))\n",
    "    return np.float32(window)\n",
    "\n",
    "\n",
    "def fig2np(fig):\n",
    "    data = np.fromstring(fig.canvas.tostring_rgb(), dtype=np.uint8, sep='')\n",
    "    data = data.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "    return data\n",
    "\n",
    "\n",
    "def plot_spectrogram_to_numpy(input_wav, fs, n_fft, n_overlap, win, mode, clim, label):\n",
    "    # cuda to cpu\n",
    "    input_wav = input_wav.cpu().detach().numpy()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 3))\n",
    "\n",
    "    if mode == 'phase':\n",
    "        pxx, freq, t, cax = plt.specgram(input_wav, NFFT=int(n_fft), Fs=int(fs), window=win, noverlap=n_overlap,\n",
    "                                         cmap='jet',\n",
    "                                         mode=mode)\n",
    "    else:\n",
    "        pxx, freq, t, cax = plt.specgram(input_wav, NFFT=int(n_fft), Fs=int(fs), window=win, noverlap=n_overlap,\n",
    "                                         cmap='jet')\n",
    "\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Frequency (Hz)')\n",
    "    plt.tight_layout()\n",
    "    plt.clim(clim)\n",
    "\n",
    "    if label is None:\n",
    "        fig.colorbar(cax)\n",
    "    else:\n",
    "        fig.colorbar(cax, label=label)\n",
    "\n",
    "    fig.canvas.draw()\n",
    "    data = fig2np(fig)\n",
    "    plt.close()\n",
    "    return data\n",
    "\n",
    "\n",
    "def plot_mask_to_numpy(mask, fs, n_fft, n_overlap, win, clim1, clim2, cmap):\n",
    "    frame_num = mask.shape[0]\n",
    "    shift_length = n_overlap\n",
    "    frame_length = n_fft\n",
    "    signal_length = frame_num * shift_length + frame_length\n",
    "\n",
    "    xt = np.arange(0, np.floor(10 * signal_length / fs) / 10, step=0.5) / (signal_length / fs) * frame_num + 1e-8\n",
    "    yt = (n_fft / 2) / (fs / 1000 / 2) * np.arange(0, (fs / 1000 / 2) + 1)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 3))\n",
    "    im = ax.imshow(np.transpose(mask), aspect='auto', origin='lower', interpolation='none', cmap=cmap)\n",
    "\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Frequency (kHz)')\n",
    "    plt.xticks(xt, np.arange(0, np.floor(10 * (signal_length / fs)) / 10, step=0.5))\n",
    "    plt.yticks(yt, np.int16(np.linspace(0, int((fs / 1000) / 2), len(yt))))\n",
    "    plt.tight_layout()\n",
    "    plt.colorbar(im, ax=ax)\n",
    "    im.set_clim(clim1, clim2)\n",
    "\n",
    "    fig.canvas.draw()\n",
    "    data = fig2np(fig)\n",
    "    plt.close()\n",
    "    return data\n",
    "\n",
    "\n",
    "def plot_error_to_numpy(estimated, target, fs, n_fft, n_overlap, win, mode, clim1, clim2, label):\n",
    "    fig, ax = plt.subplots(figsize=(12, 3))\n",
    "    if mode == None:\n",
    "        pxx1, freq, t, cax = plt.specgram(estimated, NFFT=n_fft, Fs=int(fs), window=win, noverlap=n_overlap, cmap='jet')\n",
    "        pxx2, freq, t, cax = plt.specgram(target, NFFT=n_fft, Fs=int(fs), window=win, noverlap=n_overlap, cmap='jet')\n",
    "        im = ax.imshow(10 * np.log10(pxx1) - 10 * np.log10(pxx2), aspect='auto', origin='lower', interpolation='none',\n",
    "                       cmap='jet')\n",
    "    else:\n",
    "        pxx1, freq, t, cax = plt.specgram(estimated, NFFT=n_fft, Fs=int(fs), window=win, noverlap=n_overlap, cmap='jet',\n",
    "                                          mode=mode)\n",
    "        pxx2, freq, t, cax = plt.specgram(target, NFFT=n_fft, Fs=int(fs), window=win, noverlap=n_overlap, cmap='jet',\n",
    "                                          mode=mode)\n",
    "        im = ax.imshow(pxx1 - pxx2, aspect='auto', origin='lower', interpolation='none', cmap='jet')\n",
    "\n",
    "    frame_num = pxx1.shape[1]\n",
    "    shift_length = n_overlap\n",
    "    frame_length = n_fft\n",
    "    signal_length = frame_num * shift_length + frame_length\n",
    "\n",
    "    xt = np.arange(0, np.floor(10 * (signal_length / fs)) / 10, step=0.5) / (signal_length / fs) * frame_num\n",
    "    yt = (n_fft / 2) / (fs / 1000 / 2) * np.arange(0, (fs / 1000 / 2) + 1)\n",
    "\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Frequency (kHz)')\n",
    "    plt.xticks(xt, np.arange(0, np.floor(10 * (signal_length / fs)) / 10, step=0.5))\n",
    "    plt.yticks(yt, np.int16(np.linspace(0, int((fs / 1000) / 2), len(yt))))\n",
    "    plt.tight_layout()\n",
    "    plt.colorbar(im, ax=ax, label=label)\n",
    "    im.set_clim(clim1, clim2)\n",
    "\n",
    "    fig.canvas.draw()\n",
    "    data = fig2np(fig)\n",
    "    plt.close()\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "############################################################################\n",
    "#                                for run.py                                #\n",
    "############################################################################\n",
    "def near_avg_index(array):\n",
    "    array_mean = np.mean(array)\n",
    "\n",
    "    distance_arr = []\n",
    "    for i in range(len(array)):\n",
    "        val = array[i]\n",
    "        distance = abs(array_mean - val)\n",
    "        distance_arr.append(distance)\n",
    "\n",
    "    index = distance_arr.index(min(distance_arr))\n",
    "    return index\n",
    "\n",
    "\n",
    "def max_index(array):\n",
    "    array_max = np.max(array)\n",
    "\n",
    "    for i in range(len(array)):\n",
    "        val = array[i]\n",
    "        if val == array_max:\n",
    "            index = i\n",
    "    return index\n",
    "\n",
    "\n",
    "def min_index(array):\n",
    "    array_min = np.min(array)\n",
    "\n",
    "    for i in range(len(array)):\n",
    "        val = array[i]\n",
    "        if val == array_min:\n",
    "            index = i\n",
    "    return index\n",
    "\n",
    "\n",
    "class Bar(object):\n",
    "    def __init__(self, dataloader):\n",
    "        if not hasattr(dataloader, 'dataset'):\n",
    "            raise ValueError('Attribute `dataset` not exists in dataloder.')\n",
    "        if not hasattr(dataloader, 'batch_size'):\n",
    "            raise ValueError('Attribute `batch_size` not exists in dataloder.')\n",
    "\n",
    "        self.dataloader = dataloader\n",
    "        self.iterator = iter(dataloader)\n",
    "        self.dataset = dataloader.dataset\n",
    "        self.batch_size = dataloader.batch_size\n",
    "        self._idx = 0\n",
    "        self._batch_idx = 0\n",
    "        self._time = []\n",
    "        self._DISPLAY_LENGTH = 50\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataloader)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if len(self._time) < 2:\n",
    "            self._time.append(time.time())\n",
    "\n",
    "        self._batch_idx += self.batch_size\n",
    "        if self._batch_idx > len(self.dataset):\n",
    "            self._batch_idx = len(self.dataset)\n",
    "\n",
    "        try:\n",
    "            batch = next(self.iterator)\n",
    "            self._display()\n",
    "        except StopIteration:\n",
    "            raise StopIteration()\n",
    "\n",
    "        self._idx += 1\n",
    "        if self._idx >= len(self.dataloader):\n",
    "            self._reset()\n",
    "\n",
    "        return batch\n",
    "\n",
    "    def _display(self):\n",
    "        if len(self._time) > 1:\n",
    "            t = (self._time[-1] - self._time[-2])\n",
    "            eta = t * (len(self.dataloader) - self._idx)\n",
    "        else:\n",
    "            eta = 0\n",
    "\n",
    "        rate = self._idx / len(self.dataloader)\n",
    "        len_bar = int(rate * self._DISPLAY_LENGTH)\n",
    "        bar = ('=' * len_bar + '>').ljust(self._DISPLAY_LENGTH, '.')\n",
    "        idx = str(self._batch_idx).rjust(len(str(len(self.dataset))), ' ')\n",
    "\n",
    "        tmpl = '\\r{}/{}: [{}] - ETA {:.1f}s'.format(\n",
    "            idx,\n",
    "            len(self.dataset),\n",
    "            bar,\n",
    "            eta\n",
    "        )\n",
    "        print(tmpl, end='')\n",
    "        if self._batch_idx == len(self.dataset):\n",
    "            print()\n",
    "\n",
    "    def _reset(self):\n",
    "        self._idx = 0\n",
    "        self._batch_idx = 0\n",
    "        self._time = []\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8dr6psVdoMPJ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Tools for loss"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "F4xPWf8ToOYf",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "############################################################################\n",
    "#               for model structure & loss function                        #\n",
    "############################################################################\n",
    "def remove_dc(data):\n",
    "    mean = torch.mean(data, -1, keepdim=True)\n",
    "    data = data - mean\n",
    "    return data\n",
    "\n",
    "\n",
    "def l2_norm(s1, s2):\n",
    "    # norm = torch.sqrt(torch.sum(s1*s2, 1, keepdim=True))\n",
    "    # norm = torch.norm(s1*s2, 1, keepdim=True)\n",
    "\n",
    "    norm = torch.sum(s1 * s2, -1, keepdim=True)\n",
    "    return norm\n",
    "\n",
    "\n",
    "def sdr(s1, s2, eps=1e-8):\n",
    "    sn = l2_norm(s1, s1)\n",
    "    sn_m_shn = l2_norm(s1 - s2, s1 - s2)\n",
    "    sdr_loss = 10 * torch.log10(sn**2 / (sn_m_shn**2 + eps))\n",
    "    return torch.mean(sdr_loss)\n",
    "\n",
    "\n",
    "def si_snr(s1, s2, eps=1e-8):\n",
    "    # s1 = remove_dc(s1)\n",
    "    # s2 = remove_dc(s2)\n",
    "    s1_s2_norm = l2_norm(s1, s2)\n",
    "    s2_s2_norm = l2_norm(s2, s2)\n",
    "    s_target = s1_s2_norm / (s2_s2_norm + eps) * s2\n",
    "    e_nosie = s1 - s_target\n",
    "    target_norm = l2_norm(s_target, s_target)\n",
    "    noise_norm = l2_norm(e_nosie, e_nosie)\n",
    "    snr = 10 * torch.log10((target_norm) / (noise_norm + eps) + eps)\n",
    "    return torch.mean(snr)\n",
    "\n",
    "\n",
    "def si_sdr(reference, estimation, eps=1e-8):\n",
    "    \"\"\"\n",
    "        Scale-Invariant Signal-to-Distortion Ratio (SI-SDR)\n",
    "        Args:\n",
    "            reference: numpy.ndarray, [..., T]\n",
    "            estimation: numpy.ndarray, [..., T]\n",
    "        Returns:\n",
    "            SI-SDR\n",
    "        [1] SDR– Half- Baked or Well Done?\n",
    "        http://www.merl.com/publications/docs/TR2019-013.pdf\n",
    "        >>> np.random.seed(0)\n",
    "        >>> reference = np.random.randn(100)\n",
    "        >>> si_sdr(reference, reference)\n",
    "        inf\n",
    "        >>> si_sdr(reference, reference * 2)\n",
    "        inf\n",
    "        >>> si_sdr(reference, np.flip(reference))\n",
    "        -25.127672346460717\n",
    "        >>> si_sdr(reference, reference + np.flip(reference))\n",
    "        0.481070445785553\n",
    "        >>> si_sdr(reference, reference + 0.5)\n",
    "        6.3704606032577304\n",
    "        >>> si_sdr(reference, reference * 2 + 1)\n",
    "        6.3704606032577304\n",
    "        >>> si_sdr([1., 0], [0., 0])  # never predict only zeros\n",
    "        nan\n",
    "        >>> si_sdr([reference, reference], [reference * 2 + 1, reference * 1 + 0.5])\n",
    "        array([6.3704606, 6.3704606])\n",
    "        :param reference:\n",
    "        :param estimation:\n",
    "        :param eps:\n",
    "        \"\"\"\n",
    "\n",
    "    reference_energy = torch.sum(reference ** 2, axis=-1, keepdims=True)\n",
    "\n",
    "    # This is $\\alpha$ after Equation (3) in [1].\n",
    "    optimal_scaling = torch.sum(reference * estimation, axis=-1, keepdims=True) / reference_energy + eps\n",
    "\n",
    "    # This is $e_{\\text{target}}$ in Equation (4) in [1].\n",
    "    projection = optimal_scaling * reference\n",
    "\n",
    "    # This is $e_{\\text{res}}$ in Equation (4) in [1].\n",
    "    noise = estimation - projection\n",
    "\n",
    "    ratio = torch.sum(projection ** 2, axis=-1) / torch.sum(noise ** 2, axis=-1) + eps\n",
    "\n",
    "    ratio = torch.mean(ratio)\n",
    "    return 10 * torch.log10(ratio + eps)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t-608O_vONfP",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Tools for score"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "I6JamLlgOdNO",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "###############################################################################\n",
    "#                           PESQ (another ref)                                #\n",
    "###############################################################################\n",
    "# interface to PESQ evaluation, taking in two waveforms as input\n",
    "def cal_pesq(dirty_wavs, clean_wavs):\n",
    "    scores = []\n",
    "    for i in range(len(dirty_wavs)):\n",
    "        pesq_score = pesq(fs, dirty_wavs[i], clean_wavs[i], 'wb')\n",
    "        scores.append(pesq_score)\n",
    "    return scores\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "#                                     STOI                                    #\n",
    "###############################################################################\n",
    "def cal_stoi(estimated_speechs, clean_speechs):\n",
    "    stoi_scores = []\n",
    "    for i in range(len(estimated_speechs)):\n",
    "        stoi_score = stoi(clean_speechs[i], estimated_speechs[i], cfg.fs, extended=False)\n",
    "        stoi_scores.append(stoi_score)\n",
    "    return stoi_scores\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "#                                     SNR                                     #\n",
    "###############################################################################\n",
    "def cal_snr(s1, s2, eps=1e-8):\n",
    "    signal = s2\n",
    "    mean_signal = np.mean(signal)\n",
    "    signal_diff = signal - mean_signal\n",
    "    var_signal = np.sum(np.mean(signal_diff ** 2))  # # variance of orignal data\n",
    "\n",
    "    noisy_signal = s1\n",
    "    noise = noisy_signal - signal\n",
    "    mean_noise = np.mean(noise)\n",
    "    noise_diff = noise - mean_noise\n",
    "    var_noise = np.sum(np.mean(noise_diff ** 2))  # # variance of noise\n",
    "\n",
    "    if var_noise == 0:\n",
    "        snr_score = 100  # # clean\n",
    "    else:\n",
    "        snr_score = (np.log10(var_signal/var_noise + eps))*10\n",
    "    return snr_score\n",
    "\n",
    "\n",
    "def cal_snr_array(estimated_speechs, clean_speechs):\n",
    "    snr_score = []\n",
    "    for i in range(len(estimated_speechs)):\n",
    "        snr = cal_snr(estimated_speechs[i], clean_speechs[i])\n",
    "        snr_score.append(snr)\n",
    "    return snr_score"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d3CmmLgnoOpz",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2lm9RahEoSN1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "#######################################################################\n",
    "#                            real network                             #\n",
    "#######################################################################\n",
    "class CRN(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            rnn_layers=rnn_layers,\n",
    "            rnn_units=rnn_units,\n",
    "            win_len=win_len,\n",
    "            win_inc=win_inc,\n",
    "            fft_len=fft_len,\n",
    "            win_type=window,\n",
    "            kernel_size=5\n",
    "    ):\n",
    "        '''\n",
    "            rnn_layers: the number of lstm layers in the crn\n",
    "        '''\n",
    "\n",
    "        super(CRN, self).__init__()\n",
    "\n",
    "        # for fft\n",
    "        self.win_len = win_len\n",
    "        self.win_inc = win_inc\n",
    "        self.fft_len = fft_len\n",
    "        self.win_type = win_type\n",
    "\n",
    "        input_dim = win_len\n",
    "        output_dim = win_len\n",
    "\n",
    "        self.rnn_input_size = rnn_input_size\n",
    "        self.rnn_units = rnn_units\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_layers = rnn_layers\n",
    "        self.kernel_size = kernel_size\n",
    "        kernel_num = dccrn_kernel_num\n",
    "        self.kernel_num = [2] + kernel_num\n",
    "\n",
    "        # bidirectional=True\n",
    "        bidirectional = False\n",
    "        fac = 2 if bidirectional else 1\n",
    "\n",
    "        self.stft = ConvSTFT(self.win_len, self.win_inc, fft_len, self.win_type, 'real')\n",
    "        self.istft = ConviSTFT(self.win_len, self.win_inc, fft_len, self.win_type, 'real')\n",
    "\n",
    "        self.encoder = nn.ModuleList()\n",
    "        self.decoder = nn.ModuleList()\n",
    "        for idx in range(len(self.kernel_num) - 1):\n",
    "            self.encoder.append(\n",
    "                nn.Sequential(\n",
    "                    RealConv2d(\n",
    "                        self.kernel_num[idx]//2,\n",
    "                        self.kernel_num[idx + 1]//2,\n",
    "                        kernel_size=(self.kernel_size, 2),\n",
    "                        stride=(2, 1),\n",
    "                        padding=(2, 1)\n",
    "                    ),\n",
    "                    nn.BatchNorm2d(self.kernel_num[idx + 1]//2),\n",
    "                    nn.PReLU() \n",
    "                )\n",
    "            )\n",
    "        hidden_dim = self.fft_len // (2 ** (len(self.kernel_num)))\n",
    "\n",
    "        self.enhance = nn.LSTM(\n",
    "            input_size=self.rnn_input_size,\n",
    "            hidden_size=self.rnn_units,\n",
    "            dropout=0.0,\n",
    "            bidirectional=bidirectional,\n",
    "            batch_first=False\n",
    "        )\n",
    "        self.tranform = nn.Linear(self.rnn_units, self.rnn_input_size)\n",
    "\n",
    "        if skip_type:\n",
    "            for idx in range(len(self.kernel_num) - 1, 0, -1):\n",
    "                if idx != 1:\n",
    "                    self.decoder.append(\n",
    "                        nn.Sequential(\n",
    "                            RealConvTranspose2d(\n",
    "                                self.kernel_num[idx],\n",
    "                                self.kernel_num[idx - 1]//2,\n",
    "                                kernel_size=(self.kernel_size, 2),\n",
    "                                stride=(2, 1),\n",
    "                                padding=(2, 0),\n",
    "                                output_padding=(1, 0)\n",
    "                            ),\n",
    "                            nn.BatchNorm2d(self.kernel_num[idx - 1]//2),\n",
    "                            nn.PReLU() \n",
    "                        )\n",
    "                    )\n",
    "                else:\n",
    "                    self.decoder.append(\n",
    "                        nn.Sequential(\n",
    "                            RealConvTranspose2d(\n",
    "                                self.kernel_num[idx],\n",
    "                                self.kernel_num[idx - 1]//2,\n",
    "                                kernel_size=(self.kernel_size, 2),\n",
    "                                stride=(2, 1),\n",
    "                                padding=(2, 0),\n",
    "                                output_padding=(1, 0)\n",
    "                            ),\n",
    "                        )\n",
    "                    )\n",
    "        else:\n",
    "            for idx in range(len(self.kernel_num) - 1, 0, -1):\n",
    "                if idx != 1:\n",
    "                    self.decoder.append(\n",
    "                        nn.Sequential(\n",
    "                            nn.ConvTranspose2d(\n",
    "                                self.kernel_num[idx],\n",
    "                                self.kernel_num[idx - 1],\n",
    "                                kernel_size=(self.kernel_size, 2),\n",
    "                                stride=(2, 1),\n",
    "                                padding=(2, 0),\n",
    "                                output_padding=(1, 0)\n",
    "                            ),\n",
    "                            nn.BatchNorm2d(self.kernel_num[idx - 1]),\n",
    "                            # nn.ELU()\n",
    "                            nn.PReLU()\n",
    "                        )\n",
    "                    )\n",
    "                else:\n",
    "                    self.decoder.append(\n",
    "                        nn.Sequential(\n",
    "                            nn.ConvTranspose2d(\n",
    "                                self.kernel_num[idx],\n",
    "                                self.kernel_num[idx - 1],\n",
    "                                kernel_size=(self.kernel_size, 2),\n",
    "                                stride=(2, 1),\n",
    "                                padding=(2, 0),\n",
    "                                output_padding=(1, 0)\n",
    "                            ),\n",
    "                        )\n",
    "                    )\n",
    "        self.flatten_parameters()\n",
    "\n",
    "    def flatten_parameters(self):\n",
    "        if isinstance(self.enhance, nn.LSTM):\n",
    "            self.enhance.flatten_parameters()\n",
    "\n",
    "    def forward(self, inputs, targets=0):\n",
    "\n",
    "        mags, phase = self.stft(inputs)\n",
    "\n",
    "        out = mags\n",
    "        out = out.unsqueeze(1)\n",
    "        out = out[:, :, 1:]\n",
    "        encoder_out = []\n",
    "\n",
    "        for idx, layer in enumerate(self.encoder):\n",
    "            out = layer(out)\n",
    "            #    print('encoder', out.size())\n",
    "            encoder_out.append(out)\n",
    "\n",
    "        batch_size, channels, dims, lengths = out.size()\n",
    "        out = out.permute(3, 0, 1, 2)\n",
    "\n",
    "        rnn_in = torch.reshape(out, [lengths, batch_size, channels * dims])\n",
    "        out, _ = self.enhance(rnn_in)\n",
    "        out = self.tranform(out)\n",
    "        out = torch.reshape(out, [lengths, batch_size, channels, dims])\n",
    "\n",
    "        out = out.permute(1, 2, 3, 0)\n",
    "\n",
    "        if skip_type:  # use skip connection\n",
    "            for idx in range(len(self.decoder)):\n",
    "                out = torch.cat([out, encoder_out[-1 - idx]], 1)\n",
    "                out = self.decoder[idx](out)\n",
    "                out = out[..., 1:]  #\n",
    "        else:\n",
    "            for idx in range(len(self.decoder)):\n",
    "                out = self.decoder[idx](out)\n",
    "                out = out[..., 1:]\n",
    "\n",
    "        # mask_mags = F.pad(out, [0, 0, 1, 0])\n",
    "        out = out.squeeze(1)\n",
    "\n",
    "        if direct_mapping:  # spectral mapping\n",
    "            target_mags, _ = self.stft(target)\n",
    "\n",
    "            out_real = out * torch.cos(phase)\n",
    "            out_imag = out * torch.sin(phase)\n",
    "\n",
    "            out_spec = torch.cat([out_real, out_imag], 1)\n",
    "\n",
    "            out_wav = self.istft(out_spec)\n",
    "            out_wav = torch.squeeze(out_wav, 1)\n",
    "            out_wav = torch.clamp_(out_wav, -1, 1)\n",
    "\n",
    "            return out, target_mags, out_wav\n",
    "        else:  # T-F masking\n",
    "            # mask_mags = torch.clamp_(mask_mags,0,100)\n",
    "            out = F.pad(out, [0, 0, 1, 0])\n",
    "            mask_mags = torch.tanh(out)\n",
    "            est_mags = mask_mags * mags\n",
    "            out_real = est_mags * torch.cos(phase)\n",
    "            out_imag = est_mags * torch.sin(phase)\n",
    "\n",
    "            out_spec = torch.cat([out_real, out_imag], 1)\n",
    "\n",
    "            out_wav = self.istft(out_spec)\n",
    "            out_wav = torch.squeeze(out_wav, 1)\n",
    "            out_wav = torch.clamp_(out_wav, -1, 1)\n",
    "\n",
    "            return out_wav\n",
    "\n",
    "    def get_params(self, weight_decay=0.0):\n",
    "        # add L2 penalty\n",
    "        weights, biases = [], []\n",
    "        for name, param in self.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                biases += [param]\n",
    "            else:\n",
    "                weights += [param]\n",
    "        params = [{\n",
    "            'params': weights,\n",
    "            'weight_decay': weight_decay,\n",
    "        }, {\n",
    "            'params': biases,\n",
    "            'weight_decay': 0.0,\n",
    "        }]\n",
    "        return params\n",
    "\n",
    "    def loss(self, estimated, target):\n",
    "        if current_loss == 'MSE':\n",
    "            return F.mse_loss(estimated, target, reduction='mean')\n",
    "        elif current_loss == 'SDR':\n",
    "            return -sdr(target, estimated)\n",
    "        elif current_loss == 'SI-SNR':\n",
    "            return -(si_snr(estimated, target))\n",
    "        elif current_loss == 'SI-SDR':\n",
    "            return -(si_sdr(target, estimated))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pDKYZuA-oSgZ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Ntb3y33ZoUn3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "#######################################################################\n",
    "#                             For train                               #\n",
    "#######################################################################\n",
    "def model_train(model, optimizer, train_loader, DEVICE):\n",
    "    # initialization\n",
    "    train_loss = 0\n",
    "    batch_num = 0\n",
    "\n",
    "    # arr = []\n",
    "    # train\n",
    "    model.train()\n",
    "    for inputs, targets in Bar(train_loader):\n",
    "                batch_num += 1\n",
    "\n",
    "                # to cuda\n",
    "                inputs = inputs.float().to(DEVICE)\n",
    "                targets = targets.float().to(DEVICE)\n",
    "\n",
    "                if direct_mapping:\n",
    "                  output_mag, target_mag, _ = model(inputs, targets)\n",
    "                  loss = model.loss(output_mag, target_mag)\n",
    "                else:\n",
    "                  outputs = model(inputs)\n",
    "                  loss = model.loss(outputs, targets)\n",
    "                # # if you want to check the scale of the loss\n",
    "                # print('loss: {:.4}'.format(loss))\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                train_loss += loss\n",
    "    train_loss /= batch_num\n",
    "\n",
    "    return train_loss  ##\n",
    "\n",
    "\n",
    "#######################################################################\n",
    "#                           For validation                            #\n",
    "#######################################################################\n",
    "def model_validate(model, validation_loader, dir_to_save, epoch, DEVICE):\n",
    "    # initialization\n",
    "    validation_loss = 0\n",
    "    batch_num = 0\n",
    "\n",
    "    avg_pesq = 0\n",
    "    avg_stoi = 0\n",
    "\n",
    "    all_batch_input = []\n",
    "    all_batch_target = []\n",
    "    all_batch_output = []\n",
    "\n",
    "    # for record the score each samples\n",
    "    f_score = open(dir_to_save + '/Epoch_' + '%d_SCORES' % epoch, 'a')\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "                for inputs, targets in Bar(validation_loader):\n",
    "                    batch_num += 1\n",
    "\n",
    "                    # to cuda\n",
    "                    inputs = inputs.float().to(DEVICE)\n",
    "                    targets = targets.float().to(DEVICE)\n",
    "\n",
    "                    if direct_mapping:\n",
    "                        output_mag, target_mag, outputs = model(inputs, targets, direct_mapping=True)\n",
    "                        loss = model.loss(output_mag, target_mag)\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = model.loss(outputs, targets)\n",
    "\n",
    "                    validation_loss += loss\n",
    "\n",
    "                    # estimate the output speech with pesq and stoi\n",
    "                    estimated_wavs = outputs.cpu().detach().numpy()\n",
    "                    clean_wavs = targets.cpu().detach().numpy()\n",
    "\n",
    "                    pesq = cal_pesq(estimated_wavs, clean_wavs)\n",
    "                    stoi = cal_stoi(estimated_wavs, clean_wavs)\n",
    "\n",
    "                    # pesq: 0.1 better / stoi: 0.01 better\n",
    "                    for i in range(len(pesq)):\n",
    "                        f_score.write('PESQ {:.6f} | STOI {:.6f}\\n'.format(pesq[i], stoi[i]))\n",
    "\n",
    "                    # reshape for sum\n",
    "                    pesq = np.reshape(pesq, (1, -1))\n",
    "                    stoi = np.reshape(stoi, (1, -1))\n",
    "\n",
    "                    avg_pesq += sum(pesq[0]) / len(inputs)\n",
    "                    avg_stoi += sum(stoi[0]) / len(inputs)\n",
    "\n",
    "                validation_loss /= batch_num\n",
    "                avg_pesq /= batch_num\n",
    "                avg_stoi /= batch_num\n",
    "\n",
    "                return validation_loss, avg_pesq, avg_stoi"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CJZFyj_toVbj",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Train_interface"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kicYZcSRoYNy",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "###############################################################################\n",
    "#                        Helper function definition                           #\n",
    "###############################################################################\n",
    "# Write training related parameters into the log file.\n",
    "def write_status_to_log_file(fp, total_parameters):\n",
    "    fp.write('%d-%d-%d %d:%d:%d\\n' %\n",
    "             (time.localtime().tm_year, time.localtime().tm_mon,\n",
    "              time.localtime().tm_mday, time.localtime().tm_hour,\n",
    "              time.localtime().tm_min, time.localtime().tm_sec))\n",
    "    fp.write('total params   : %d (%.2f M, %.2f MBytes)\\n' %\n",
    "             (total_parameters,\n",
    "              total_parameters / 1000000.0,\n",
    "              total_parameters * 4.0 / 1000000.0))\n",
    "\n",
    "\n",
    "# Calculate the size of total network.\n",
    "def calculate_total_params(our_model):\n",
    "    total_parameters = 0\n",
    "    for variable in our_model.parameters():\n",
    "        shape = variable.size()\n",
    "        variable_parameters = 1\n",
    "        for dim in shape:\n",
    "            variable_parameters *= dim\n",
    "        total_parameters += variable_parameters\n",
    "\n",
    "    return total_parameters\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "#         Parameter Initialization and Setting for model training             #\n",
    "###############################################################################\n",
    "# Set device\n",
    "DEVICE = torch.device('cpu' ) # if you want to run the code with 'cpu', change 'cpu'\n",
    "\n",
    "# Set model\n",
    "model = CRN().to(DEVICE)\n",
    "# Set optimizer and learning rate\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "total_params = calculate_total_params(model)\n",
    "\n",
    "###############################################################################\n",
    "#                        Confirm model information                            #\n",
    "###############################################################################\n",
    "print('%d-%d-%d %d:%d:%d\\n' %\n",
    "      (time.localtime().tm_year, time.localtime().tm_mon,\n",
    "       time.localtime().tm_mday, time.localtime().tm_hour,\n",
    "       time.localtime().tm_min, time.localtime().tm_sec))\n",
    "print('total params   : %d (%.2f M, %.2f MBytes)\\n' %\n",
    "      (total_params,\n",
    "       total_params / 1000000.0,\n",
    "       total_params * 4.0 / 1000000.0))\n",
    "\n",
    "###############################################################################\n",
    "#                              Create Dataloader                              #\n",
    "###############################################################################\n",
    "train_loader = create_dataloader(mode='train')\n",
    "validation_loader = create_dataloader(mode='valid')\n",
    "\n",
    "###############################################################################\n",
    "#                        Set a log file to store progress.                    #\n",
    "#               Set a hps file to store hyper-parameters information.         #\n",
    "###############################################################################\n",
    "if chkpt_model is not None:  # Load the checkpoint\n",
    "    print('Resuming from checkpoint: %s' % chkpt_path)\n",
    "\n",
    "    # Set a log file to store progress.\n",
    "    dir_to_save = job_dir + chkpt_model\n",
    "\n",
    "    checkpoint = torch.load(chkpt_path)\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    epoch_start_idx = checkpoint['epoch'] + 1\n",
    "    mse_vali_total = np.load(str(dir_to_save + '/mse_vali_total.npy'))\n",
    "else:  # First learning\n",
    "    print('Starting new training run...')\n",
    "    epoch_start_idx = 1\n",
    "    mse_vali_total = np.zeros(max_epochs)\n",
    "\n",
    "    # Set a log file to store progress.\n",
    "    dir_to_save = job_dir + expr_num + '_%d.%d' % (time.localtime().tm_mon,\n",
    "                                                           time.localtime().tm_mday) + '_%s' % current_model + '_%s' % current_loss\n",
    "\n",
    "# make the file directory\n",
    "if not os.path.exists(dir_to_save):\n",
    "    os.mkdir(dir_to_save)\n",
    "\n",
    "# logging\n",
    "log_fname = str(dir_to_save + '/log.txt')\n",
    "fp = open(log_fname, 'w')\n",
    "write_status_to_log_file(fp, total_params)\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "###############################################################################\n",
    "#                             Main program start !!                           #\n",
    "###############################################################################\n",
    "###############################################################################\n",
    "\n",
    "###############################################################################\n",
    "#                                    Train                                    #\n",
    "###############################################################################\n",
    "for epoch in range(epoch_start_idx, max_epochs):\n",
    "        start_time = time.time()\n",
    "        # Training\n",
    "        train_loss = model_train(model, optimizer, train_loader, DEVICE)\n",
    "\n",
    "        # save checkpoint file to resume training\n",
    "        save_path = str(dir_to_save + '/' + ('chkpt_%d.pt' % epoch))\n",
    "        torch.save({\n",
    "            'model': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'epoch': epoch\n",
    "        }, save_path)\n",
    "\n",
    "        # Validation\n",
    "        vali_loss, vali_pesq, vali_stoi = \\\n",
    "        model_validate(model, validation_loader, dir_to_save, epoch, DEVICE)\n",
    "\n",
    "        print('Epoch [{}] | T {:.6f} | V {:.6} takes {:.2f} seconds\\n'\n",
    "                  .format(epoch, train_loss, vali_loss, time.time() - start_time))\n",
    "        print('          | V PESQ: {:.6f} | STOI: {:.6f} '.format(vali_pesq, vali_stoi))\n",
    "        # log file save\n",
    "        fp.write('Epoch [{}] | T {:.6f} | V {:.6} takes {:.2f} seconds\\n'\n",
    "                     .format(epoch, train_loss, vali_loss, time.time() - start_time))\n",
    "        fp.write('          | V PESQ: {:.6f} | STOI: {:.6f} \\n'.format(vali_pesq, vali_stoi))\n",
    "\n",
    "        mse_vali_total[epoch - 1] = vali_loss\n",
    "        np.save(str(dir_to_save + '/mse_vali_total.npy'), mse_vali_total)\n",
    "\n",
    "\n",
    "fp.close()\n",
    "print('Training has been finished.')\n",
    "\n",
    "# Copy optimum model that has minimum MSE.\n",
    "print('Save optimum models...')\n",
    "min_index = np.argmin(mse_vali_total)\n",
    "print('Minimum validation loss is at ' + str(min_index + 1) + '.')\n",
    "src_file = str(dir_to_save + '/' + ('chkpt_%d.pt' % (min_index + 1)))\n",
    "tgt_file = str(dir_to_save + '/chkpt_opt.pt')\n",
    "shutil.copy(src_file, tgt_file)"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}